{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d33c6704",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os.path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f47f02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = Path('Dog and Cat .png');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6f95968",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filepaths = list(image_dir.glob(r'**/*.png'))\n",
    "labels = list(map(lambda x: os.path.split(os.path.split(x)[0])[1], filepaths))\n",
    "\n",
    "filepaths = pd.Series(filepaths, name='Filepath').astype(str)\n",
    "labels = pd.Series(labels, name='Label')\n",
    "\n",
    "image_df = pd.concat([filepaths, labels], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cea2dd70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filepath</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dog and Cat .png\\Cat\\1.png</td>\n",
       "      <td>Cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dog and Cat .png\\Cat\\10.png</td>\n",
       "      <td>Cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dog and Cat .png\\Cat\\100.png</td>\n",
       "      <td>Cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dog and Cat .png\\Cat\\101.png</td>\n",
       "      <td>Cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dog and Cat .png\\Cat\\102.png</td>\n",
       "      <td>Cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>Dog and Cat .png\\Dog\\g95.png</td>\n",
       "      <td>Dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>Dog and Cat .png\\Dog\\g96.png</td>\n",
       "      <td>Dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>Dog and Cat .png\\Dog\\g97.png</td>\n",
       "      <td>Dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Dog and Cat .png\\Dog\\g98.png</td>\n",
       "      <td>Dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>Dog and Cat .png\\Dog\\g99.png</td>\n",
       "      <td>Dog</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>999 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Filepath Label\n",
       "0      Dog and Cat .png\\Cat\\1.png   Cat\n",
       "1     Dog and Cat .png\\Cat\\10.png   Cat\n",
       "2    Dog and Cat .png\\Cat\\100.png   Cat\n",
       "3    Dog and Cat .png\\Cat\\101.png   Cat\n",
       "4    Dog and Cat .png\\Cat\\102.png   Cat\n",
       "..                            ...   ...\n",
       "994  Dog and Cat .png\\Dog\\g95.png   Dog\n",
       "995  Dog and Cat .png\\Dog\\g96.png   Dog\n",
       "996  Dog and Cat .png\\Dog\\g97.png   Dog\n",
       "997  Dog and Cat .png\\Dog\\g98.png   Dog\n",
       "998  Dog and Cat .png\\Dog\\g99.png   Dog\n",
       "\n",
       "[999 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aaac4a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(image_df, train_size=0.7, shuffle=True, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3330ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    horizontal_flip=True,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "test_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale=1./255\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "adee8966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 560 validated image filenames belonging to 2 classes.\n",
      "Found 139 validated image filenames belonging to 2 classes.\n",
      "Found 300 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_images = train_generator.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    x_col='Filepath',\n",
    "    y_col='Label',\n",
    "    target_size=(224, 224),\n",
    "    color_mode='rgb',\n",
    "    class_mode='binary',\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    seed=42,\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "val_images = train_generator.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    x_col='Filepath',\n",
    "    y_col='Label',\n",
    "    target_size=(224, 224),\n",
    "    color_mode='rgb',\n",
    "    class_mode='binary',\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    seed=42,\n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "test_images = test_generator.flow_from_dataframe(\n",
    "    dataframe=test_df,\n",
    "    x_col='Filepath',\n",
    "    y_col='Label',\n",
    "    target_size=(224, 224),\n",
    "    color_mode='rgb',\n",
    "    class_mode='binary',\n",
    "    batch_size=32,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba17ed6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "18/18 [==============================] - 23s 1s/step - loss: 0.6948 - accuracy: 0.4839 - val_loss: 0.6927 - val_accuracy: 0.5036 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "18/18 [==============================] - 24s 1s/step - loss: 0.6911 - accuracy: 0.5375 - val_loss: 0.6918 - val_accuracy: 0.5036 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "18/18 [==============================] - 22s 1s/step - loss: 0.6890 - accuracy: 0.5375 - val_loss: 0.6897 - val_accuracy: 0.4892 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "18/18 [==============================] - 21s 1s/step - loss: 0.6777 - accuracy: 0.5839 - val_loss: 0.6854 - val_accuracy: 0.5324 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "18/18 [==============================] - 20s 1s/step - loss: 0.6544 - accuracy: 0.6196 - val_loss: 0.6895 - val_accuracy: 0.5683 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "18/18 [==============================] - 20s 1s/step - loss: 0.6348 - accuracy: 0.6536 - val_loss: 0.6966 - val_accuracy: 0.5683 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "18/18 [==============================] - 20s 1s/step - loss: 0.6232 - accuracy: 0.6411 - val_loss: 0.7050 - val_accuracy: 0.5612 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "18/18 [==============================] - 21s 1s/step - loss: 0.6175 - accuracy: 0.6607 - val_loss: 0.7119 - val_accuracy: 0.5396 - lr: 1.0000e-04\n",
      "Epoch 9/50\n",
      "18/18 [==============================] - 20s 1s/step - loss: 0.6125 - accuracy: 0.6518 - val_loss: 0.7114 - val_accuracy: 0.5324 - lr: 1.0000e-04\n"
     ]
    }
   ],
   "source": [
    "inputs = tf.keras.Input(shape=(224, 224, 3))\n",
    "x = tf.keras.layers.Conv2D(filters=16, kernel_size=(3, 3), activation='relu')(inputs)\n",
    "x = tf.keras.layers.MaxPool2D()(x)\n",
    "x = tf.keras.layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu')(x)\n",
    "x = tf.keras.layers.MaxPool2D()(x)\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = tf.keras.layers.Dense(128, activation='relu')(x)\n",
    "x = tf.keras.layers.Dense(128, activation='relu')(x)\n",
    "outputs = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    train_images,\n",
    "    validation_data=val_images,\n",
    "    epochs=50,\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=5,\n",
    "            restore_best_weights=True\n",
    "        ),\n",
    "        tf.keras.callbacks.ReduceLROnPlateau(\n",
    "            monitor='val_loss',\n",
    "            patience=3\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd36f39a",
   "metadata": {},
   "source": [
    "Resultatai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d40bd9c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Test Loss: 0.68283\n",
      "Test Accuracy: 55.67%\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(test_images, verbose=0)\n",
    "\n",
    "print(\"    Test Loss: {:.5f}\".format(results[0]))\n",
    "print(\"Test Accuracy: {:.2f}%\".format(results[1] * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4135b7d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Armin\\AppData\\Local\\Temp/ipykernel_18028/1801417715.py:1: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  predictions = (model.predict(test_images) >= 0.5).astype(np.int)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAGDCAYAAAAoI6sGAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAY7ElEQVR4nO3deZhcZZmw8fvJAglrQggJ+w6yBhUQEAKIgqAM4oDAsIlIEESHTfCbUbaBGVBkUREEHHHYcQSRNSyyzzgkREIIssgelhCChC1A6DzfH3U6dJp0p4l9upJ+79915aLrnKpz3o7lnVNvnToVmYkkqffr0+wBSJJ6hsGXpEIYfEkqhMGXpEIYfEkqhMGXpEIYfPUaETEwIq6LiGkR8du/Yzt7R8Qt3Tm2ZoiImyJi/2aPQ/MPg68eFxH/FBFjI+KtiHipCtOW3bDp3YBhwJDM3H1eN5KZl2bm9t0wntlExDYRkRFxdbvlI6rld3ZxOydExCVzu19m7piZv5nH4aoXMvjqURFxJHAW8O804rwS8Atgl27Y/MrA45n5QTdsqy5TgC0iYkibZfsDj3fXDqLB/2/rI3xSqMdExJLAScC3M/PqzHw7M2dk5nWZ+b3qPgtHxFkR8WL156yIWLhat01ETIqIoyLilerVwQHVuhOB44A9qlcOB7Y/Eo6IVaoj6X7V7a9HxFMR8WZEPB0Re7dZfm+bx20REWOqqaIxEbFFm3V3RsS/RcR91XZuiYilO/lreB/4PbBn9fi+wNeAS9v9XZ0dEc9HxBsR8UBEbFUt/yLwL21+z/FtxnFKRNwHvAOsVi37ZrX+3Ij47zbbPy0ibo+I6Or/flrwGXz1pM2BAcA1ndznX4HNgI2AEcCmwA/arB8OLAksDxwInBMRgzPzeBqvGq7MzMUy81edDSQiFgV+CuyYmYsDWwAPzuF+SwE3VPcdApwB3NDuCP2fgAOAZYCFgKM72zfwX8B+1c87ABOBF9vdZwyNv4OlgMuA30bEgMy8ud3vOaLNY/YFRgGLA8+2295RwIbVP2Zb0fi72z+9tkpRDL560hDg1blMuewNnJSZr2TmFOBEGiFrNaNaPyMzbwTeAtaex/HMBNaPiIGZ+VJmTpzDfb4EPJGZF2fmB5l5OfAosHOb+/w6Mx/PzOnAVTRC3aHM/B9gqYhYm0b4/2sO97kkM6dW+/wJsDBz/z0vysyJ1WNmtNveO8A+NP7BugT4TmZOmsv21MsYfPWkqcDSrVMqHViO2Y9On62WzdpGu38w3gEW+7gDycy3gT2AbwEvRcQNEfGJLoyndUzLt7n98jyM52LgMGBb5vCKp5q2+ks1jfQ6jVc1nU0VATzf2crMvB94Cgga/zCpMAZfPel/gXeBr3RynxdpvPnaaiU+Ot3RVW8Di7S5PbztyswcnZlfAJalcdR+QRfG0zqmF+ZxTK0uBg4FbqyOvmepplyOpTG3PzgzBwHTaIQaoKNpmE6nZyLi2zReKbwIHDPPI9cCy+Crx2TmNBpvrJ4TEV+JiEUion9E7BgRP6rudjnwg4gYWr35eRyNKYh58SAwMiJWqt4w/n+tKyJiWET8QzWX/x6NqaGWOWzjRmCt6lTSfhGxB7AucP08jgmAzHwa2JrGexbtLQ58QOOMnn4RcRywRJv1k4FVPs6ZOBGxFnAyjWmdfYFjImKjeRu9FlQGXz0qM88AjqTxRuwUGtMQh9E4cwUaURoLPARMAMZVy+ZlX7cCV1bbeoDZI92HxhuZLwKv0YjvoXPYxlTgy9V9p9I4Mv5yZr46L2Nqt+17M3NOr15GAzfROFXzWRqvitpO17R+qGxqRIyb236qKbRLgNMyc3xmPkHjTJ+LW8+AUhnCN+klqQwe4UtSIQy+JBXC4EtSIQy+JBXC4EtSITr7xGNTDT3gSk8f0nyrT1+PlTR/mnzh7h1eEM9nrSQVwuBLUiEMviQVwuBLUiEMviQVwuBLUiEMviQVwuBLUiEMviQVwuBLUiEMviQVwuBLUiEMviQVwuBLUiEMviQVwuBLUiEMviQVwuBLUiEMviQVwuBLUiEMviQVwuBLUiEMviQVwuBLUiEMviQVwuBLUiEMviQVwuBLUiEMviQVwuBLUiEMviQVwuBLUiEMviQVwuBLUiEMviQVwuBLUiEMviQVwuBLUiEMviQVwuBLUiEMviQVwuBLUiEMviQVwuBLUiEMviQVwuBLUiEMviQVwuBLUiEMviQVwuBLUiEMviQVwuBLUiEMviQVwuBLUiEMviQVwuBLUiEMviQVwuBLUiEMviQVwuBLUiEMviQVwuBLUiEMviQVwuBLUiEMviQVwuBLUiEMviQVwuBLUiEMviQVwuBLUiEMviQVwuBLUiFqCX5E9Ktju5KkeVfXEf79NW1XkjSP6gp+1LRdSdI8qmvqZWhEHNnRysw8o6b9SpI6UFfw+wKL4ZF+j1t9+OJceMjms26vPHQxTrvmYZZYpD/7br0aU998D4BTfjeB2x56qVnDVKFWH7YY5x/c9vm5KD+6diLn3/YEAIdsvxYnfG0E6xx+La+99X6zhtlr1RX8lzLzpJq2rU48+fKbbHv8LQD0iWDCmTtzw7hJ7LXlqpx3y+P84ubHmjxClezJyW+x3Um3AtAnYPzpO3PjuBcAWG7wQLZedxjPT327mUPs1Xp0Dj8iVoyI79W0T7Uzct1leOaVt5k09Z1mD0X6iK3WGcYzU95i0muN5+dJe2zESf/9EJlNHlgvVlfwt2v9ISKWjohDIuJu4C5gWE37VDu7fmYlrv6/Z2fdPnC7NbnzpB04+xubsOQi/Zs4Mgl23XRFrvm/5wDYYcSyvPz6dB6ZNK3Jo+rd6gr+jIjYLyJupnGK5hrAapm5WmYe3dGDImJURIyNiLHvPnZbTUMrQ/++fdhho+X5w5jnAbjojr+yyTE3sO3xo5n8+ructOdGzR2gita/b7D9iOW47oFJDFyoL4d/aR1Ou/bhZg+r16sr+K8ABwKnAKtn5lHAXN+ByczzM3PjzNx4wNqfr2loZdhuw+E89OzfmPJG403aKW+8x8xMMuHiu57kk6sOafIIVbLtNliWCc81np+rDF2UlZZelD8evz1jTt2J5QYP5NYffoGhSyzc7GH2OnW9afsvwJ7AucBlEXFlTftRB776mZVnvVwGGLbkACZPexeAnT69Ao++4EtnNc+um67INfc3Xn3+5YU3WO/I62atG3PqTuxw8m2epVODWoKfmWcCZ0bEasBewO+B5SLiGOD3mfl4HftVw8CF+rL1esM46jdjZy077msjWH+lQWTC86++zdFt1kk9aeBCfRm57jCOvviBZg+lOJE1vCUeEWsAwzLzvjbLNgTOArbOzL5z28bQA670vXrNt/r09bqDmj9NvnD3Dj//VNez9izgzbYLMvMh4Fjgppr2KUnqRF3BX6UK/Gwycwywck37lCR1oq7gD+hk3cCa9ilJ6kRdwR8TEQe1XxgRBwK+UyNJTVDXaZmHA9dExN58GPiNgYWAXWvapySpE3WdljkZ2CIitgXWrxbfkJl/rGN/kqS5q/WrCDPzDuCOOvchSeoaTyaWpEIYfEkqhMGXpEIYfEkqhMGXpEIYfEkqhMGXpEIYfEkqhMGXpEIYfEkqhMGXpEIYfEkqhMGXpEIYfEkqhMGXpEIYfEkqhMGXpEIYfEkqhMGXpEIYfEkqhMGXpEIYfEkqhMGXpEIYfEkqhMGXpEIYfEkqhMGXpEIYfEkqhMGXpEIYfEkqhMGXpEIYfEkqhMGXpEIYfEkqhMGXpEIYfEkqhMGXpEIYfEkqhMGXpEIYfEkqhMGXpEIYfEkqhMGXpEIYfEkqhMGXpEIYfEkqhMGXpEIYfEkqhMGXpEIYfEkqhMGXpEIYfEkqhMGXpEIYfEkqhMGXpEIYfEkqhMGXpEL062hFRPwMyI7WZ+Z3axmRJKkWHQYfGNtjo5Ak1a7D4Gfmb3pyIJKkenV2hA9ARAwFjgXWBQa0Ls/Mz9U4LklSN+vKm7aXAn8BVgVOBJ4BxtQ4JklSDboS/CGZ+StgRmbelZnfADareVySpG421ykdYEb135ci4kvAi8AK9Q1JklSHrgT/5IhYEjgK+BmwBHBEraOSJHW7uQY/M6+vfpwGbFvvcCRJdenKWTq/Zg4fwKrm8iVJC4iuTOlc3+bnAcCuNObxJUkLkK5M6fyu7e2IuBy4rbYRSZJqMS8XT1sTWKm7ByJJqldX5vDfZPY5/JdpfPK2Vuts4Jmfmn+NufjyZg9B6sDuHa7pypTO4t06FklSU8x1Sicibu/KMknS/K2z6+EPABYBlo6IwUBUq5YAluuBsUmSulFnUzoHA4fTiPsDfBj8N4Bz6h2WJKm7dXY9/LOBsyPiO5n5sx4ckySpBl05LXNmRAxqvRERgyPi0PqGJEmqQ1eCf1Bmvt56IzP/BhxU24gkSbXoSvD7RETr/D0R0RdYqL4hSZLq0JVr6YwGroqI82h8AOtbwE21jkqS1O26EvxjgVHAITTO1PkzsGydg5Ikdb+5Tulk5kzgT8BTwMbAdjS+41aStADp7INXawF7AnsBU4ErATLTL0GRpAVQZ1M6jwL3ADtn5l8BIsKvNpSkBVRnUzr/SOPKmHdExAURsR0fftpWkrSA6TD4mXlNZu4BfAK4k8YXlw+LiHMjYvseGp8kqZt05U3btzPz0sz8MrAC8CDw/boHJknqXh/rG68y87XM/GVmfq6uAUmS6jEvX3EoSVoAGXxJKoTBl6RCGHxJKoTBl6RCGHxJKoTBl6RCGHxJKoTBl6RCGHxJKoTBl6RCGHxJKoTBl6RCGHxJKoTBl6RCGHxJKoTBl6RCGHxJKoTBl6RCGHxJKoTBl6RCGHxJKoTBl6RCGHxJKoTBl6RCGHxJKoTBl6RCGHxJKoTBl6RCGHxJKoTBl6RCGHxJKoTBl6RCGHxJKoTBl6RCGHxJKoTBl6RCGHxJKoTBl6RCGHxJKoTBl6RCGHxJKoTBl6RCGHxJKoTBl6RCGHxJKoTBl6RCGHxJKoTBl6RCGHxJKoTBl6RCGHxJKoTBl6RCGHxJKkS/OjYaEUsAwzLzier27sDAavXozJxcx34lSR2r6wj/dOCzbW7/B7AJMBI4saZ9SpI6UcsRPo24H9zm9puZ+R2AiLi3pn1KkjpR1xF+v8zMNrf3bfPzoJr2KUnqRF3BnxkRw1tvZObDABGxPDCzpn1KkjpR15TOj4HrIuIo4M/Vsk/RmNv/cU37VOXKAz/N9BkttMxMWmbCqMvGs/rSi3DU51dnkYX68tK09/i3mx7nnfdbmj1UFejbe23DAV/dgojg11ffx88vu5N/P/wr7DRyfd6f0cLTk15l1PGXMO2t6c0eaq9TS/Az85KIeBU4GVivWvwwcFxm3lTHPjW7f77qYaa9+8Gs28dsvwa/uPsZxk96g53WW4a9Nl6eX/3Pc00coUq07urLcsBXt2CrfX/M+zNa+MM5h3LTvRO5/U+P8sOf/YGWlpmc/N1d+N43tucHP7222cPtdWo7Dz8zb87MkZk5pPqztbFvnpUGD2T8pDcAGPvs62y95pAmj0gl+sSqw7l/wjNMf3cGLS0zueeBv7LLtiO4/U+P0tLSmO29f8LTLD9sUHMH2kvVFvyI2DEi7oqIVyNiSvXzTnXtT7P7yT+uxwV7j2DnDYYB8PTUd9hy9aUA2GatpVlm8YWbOTwVauKTL7Llp9ZgqSUXZeCA/nxxy/VYYfjg2e6z3y6bM/q+R5o0wt6trg9eHUTjtMxjgLHV4o2BUyNihcw8v4PHjQJGAayx2/dYdvNd6hher3foFROY+vb7DBrYnzN2W4/nXpvOqaP/yj9vuyr7b7Yi9z35GjNafO9cPe+xpyfzk4tu5fpzD+Pt6e/x0OMv8MEHH76XdMyBO9DSMpMrbhzTxFH2XjH72ZPdtNGIR4AtM/O1dsuHAPdm5jpz28bIM+7r/oEV6IDNV2T6+y1c8cCLs5atMGgAP9xpLQ6+7KEmjmzBNubiy5s9hF7hxMN25oXJr3P+b+9h750/w0G7bcmOB/+U6e/OaPbQFljT//zz6GhdXVM60T72AJk5tab9qTKgXx8G9u876+dNVh7EU1PfYdDA/gAEsN9mK3Lt+JebOEqVbOjgxQBYcfhgdvncCK66eSxf2GIdjvr659nt8F8a+xrVdVrmGxExIjPHt10YESOAN2vap4DBi/bnlH9ovIDqG8Ftj07h/mdeZ7dPLsuuGy0LwN1PTOXGia80c5gq2OWnf5OlBi3KjA9aOPzUq3j9zemceezXWHihflx/7mEA3D/hGb57yhVNHmnvU9eUzpbApcCvgQeApHG5hf2BfTJzrpdXcEpH8zOndDS/6vEpnSron6m2/3XgG9XPm3Ul9pKk7lfXlA6Z+TJwXEQMrW5PqWtfkqS5q+UIPxpOiIgpwKPAY9W5+MfVsT9J0tzVdZbO4TSuh79p9SnbpWhM8Xw2Io6oaZ+SpE7UFfz9gL0y8+nWBZn5FLBPtU6S1MPqCn7/zHy1/cJqHr9/TfuUJHWiruC/P4/rJEk1qessnRER8cYclgcwoKZ9SpI6Udf18PvWsV1J0ryr7fLIkqT5i8GXpEIYfEkqhMGXpEIYfEkqhMGXpEIYfEkqhMGXpEIYfEkqhMGXpEIYfEkqhMGXpEIYfEkqhMGXpEIYfEkqhMGXpEIYfEkqhMGXpEIYfEkqhMGXpEIYfEkqhMGXpEIYfEkqhMGXpEIYfEkqhMGXpEIYfEkqhMGXpEIYfEkqhMGXpEIYfEkqhMGXpEIYfEkqhMGXpEIYfEkqhMGXpEIYfEkqhMGXpEIYfEkqhMGXpEIYfEkqhMGXpEIYfEkqhMGXpEIYfEkqhMGXpEIYfEkqhMGXpEIYfEkqhMGXpEIYfEkqhMGXpEIYfEkqhMGXpEIYfEkqhMGXpEIYfEkqhMGXpEIYfEkqhMGXpEIYfEkqhMGXpEIYfEkqhMGXpEIYfEkqhMGXpEIYfEkqhMGXpEJEZjZ7DOoBETEqM89v9jik9nxu9hyP8MsxqtkDkDrgc7OHGHxJKoTBl6RCGPxyOEeq+ZXPzR7im7aSVAiP8CWpEAa/l4iI4RFxRUQ8GRGPRMSNEbFWte6IiHg3IpaMiCER8WD15+WIeKHN7YWa/Xuo94iIlup5NTEixkfEkRHRp836LSPi/oh4tPozqt3j94mIh9o8/sKIGNTjv0gv0q/ZA9DfLyICuAb4TWbuWS3bCBgGPA7sBYwBds3Mi4CNqvucALyVmaf3+KBVgumZuRFARCwDXAYsCRwfEcOr21/JzHERsTQwOiJeyMwbIuKLwBHAjpn5QkT0Bfan8Zx+vQm/S6/gEX7vsC0wIzPPa12QmQ9m5j0RsTqwGPADGuGXelxmvkLjfPvDqgOUbwMXZea4av2rwDHA96uH/CtwdGa+UK1vycz/zMzHen70vYfB7x3WBx7oYN1ewOXAPcDa1ZGW1OMy8ykazVkGWI+PPmfHVsup/juu50ZXBoPf++0JXJGZM4Grgd2bPB6VLdr8d06nCH5kWURsUL0X8GRE7FHr6Ho5g987TAQ+3X5hRGwIrAncGhHP0Ii/0zpqiohYDWgBXqHxnN243V0+DTxS/TwR+BRAZk6o3gu4CRjYI4PtpQx+7/BHYOGIOKh1QURsApwNnJCZq1R/lgOWj4iVmzVQlSkihgLnAT/Pxod/zgG+Xp1cQEQMAU4DflQ95D+A0yNihTabMfZ/J8/S6QUyMyNiV+CsiPg+8C7wDLANcEi7u19D40j/tJ4co4o0MCIeBPoDHwAXA2cAZOZLEbEPcEFELE5jiueszLyuWn9j9Y/ETdUZOq8DDwOje/y36EX8pK0kFcIpHUkqhMGXpEIYfEkqhMGXpEIYfEkqhMFXr9Xmao0PR8RvI2KRv2NbF0XEbtXPF0bEup3cd5uI2GIe9vFMdRExqRYGX73Z9MzcKDPXB94HvtV2ZXV+98eWmd/MzEc6ucs2wMcOvlQ3g69S3AOsUR193xERlwETIqJvRPw4IsZU114/GBqXnI6In1ffLXADjQt+Ua27MyI2rn7+YkSMq67XfntErELjH5YjqlcXW0XE0Ij4XbWPMRHx2eqxQyLiloj4c0T8kg+vMyPVwk/aqteLiH7AjsDN1aJNgfUz8+nqSzemZeYmEbEwcF9E3AJ8Elgb2IDGNdgfAf6z3XaHAhcAI6ttLZWZr0XEebT5noHqH5czM/PeiFiJxqdF1wGOB+7NzJMi4ks0Lh8s1cbgqzdr/Wg/NI7wf0VjquX+zHy6Wr49sGHr/DyNL+hYExgJXJ6ZLcCLEfHHOWx/M+Du1m1l5msdjOPzwLqNy8ADsER1OYGRwFerx94QEX+bt19T6hqDr95s1jcutaqi+3bbRcB3MnN0u/vtxJwv3zvb3bpwH2hMnW6emdPnMBavbaIe4xy+SjcaOCQi+gNExFoRsShwN7BnNce/LI1vFWvvf4GtI2LV6rFLVcvfBBZvc79bgMNab7ReIbLax97Vsh2Bwd31S0lzYvBVugtpzM+Pi4iHgV/SeOV7DfAEMAE4F7ir/QMzcwqNeferI2I8cGW16jpg19Y3bYHvAhtXbwo/wodnC50IjIyIcTSmlp6r6XeUAK+WKUnF8Ahfkgph8CWpEAZfkgph8CWpEAZfkgph8CWpEAZfkgph8CWpEP8f4V8tGpHMQy4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "----------------------\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         CAT       0.56      0.50      0.53       149\n",
      "         DOG       0.55      0.61      0.58       151\n",
      "\n",
      "    accuracy                           0.56       300\n",
      "   macro avg       0.56      0.56      0.56       300\n",
      "weighted avg       0.56      0.56      0.56       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = (model.predict(test_images) >= 0.5).astype(np.int)\n",
    "\n",
    "cm = confusion_matrix(test_images.labels, predictions, labels=[0, 1])\n",
    "clr = classification_report(test_images.labels, predictions, labels=[0, 1], target_names=[\"CAT\", \"DOG\"])\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='g', vmin=0, cmap='Blues', cbar=False)\n",
    "plt.xticks(ticks=[0.5, 1.5], labels=[\"CAT\", \"DOG\"])\n",
    "plt.yticks(ticks=[0.5, 1.5], labels=[\"CAT\", \"DOG\"])\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n",
    "\n",
    "print(\"Classification Report:\\n----------------------\\n\", clr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
